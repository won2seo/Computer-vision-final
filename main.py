import os
import glob
import pandas as pd
import whisper
import torch
import librosa
import numpy as np
from transformers import BertForSequenceClassification, AutoTokenizer, TextClassificationPipeline
import warnings

# ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore")

class AudioDatasetGenerator:
    def __init__(self):
        print("ğŸ”„ [Init] ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... (Text + Audio Volume ë¶„ì„)")
        
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"   ğŸ‘‰ ì‚¬ìš© ì¥ì¹˜: {self.device}")

        # 1. Whisper ëª¨ë¸ (Medium)
        try:
            self.stt_model = whisper.load_model("medium", device=self.device)
            print("   âœ… Whisper 'Medium' ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"   âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ 'Small' ëª¨ë¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. ({e})")
            self.stt_model = whisper.load_model("small", device=self.device)

        # 2. Unsmile BERT (ìš•ì„¤ í…ìŠ¤íŠ¸ ê°ì§€)
        model_name = 'smilegate-ai/kor_unsmile'
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.nlp_model = BertForSequenceClassification.from_pretrained(model_name)
            
            self.pipe = TextClassificationPipeline(
                model=self.nlp_model, 
                tokenizer=self.tokenizer, 
                device=0 if self.device == "cuda" else -1,
                return_all_scores=True
            )
            print("   âœ… Unsmile BERT ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"âŒ BERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            exit()

    def detect_shouting(self, file_path, threshold=0.5):
        """
        ğŸ”Š ì˜¤ë””ì˜¤ì˜ ë³¼ë¥¨(RMS ì—ë„ˆì§€)ì„ ë¶„ì„í•´ ê³ í•¨/ë¹„ëª… ì—¬ë¶€ íŒë‹¨
        threshold: ê³ í•¨ìœ¼ë¡œ íŒë‹¨í•  ê¸°ì¤€ ë³¼ë¥¨ (0.0 ~ 1.0)
        """
        try:
            # ë¹ ë¥¸ ë¶„ì„ì„ ìœ„í•´ ìµœëŒ€ 60ì´ˆê¹Œì§€ë§Œ ë¡œë“œ
            y, sr = librosa.load(file_path, sr=16000, duration=60)
            
            # ì†Œë¦¬ í¬ê¸°(RMS) ê³„ì‚°
            rms = librosa.feature.rms(y=y)[0]
            
            if len(rms) == 0:
                return False, 0.0

            # ì „ì²´ í‰ê· ì´ ì•„ë‹ˆë¼, 'ìˆœê°„ ìµœëŒ€ ë³¼ë¥¨'ì„ ì²´í¬
            max_vol = np.max(rms)
            
            # ê¸°ì¤€ê°’ë³´ë‹¤ í¬ë©´ ê³ í•¨ìœ¼ë¡œ íŒë‹¨
            is_shouting = max_vol > threshold
            return is_shouting, max_vol
            
        except Exception as e:
            print(f"   âš ï¸ ë³¼ë¥¨ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return False, 0.0

    def analyze_file(self, file_path):
        filename = os.path.basename(file_path)
        print(f"\nğŸ“‚ ë¶„ì„ ì¤‘ì¸ íŒŒì¼: {filename}")
        
        # [Step 1] ê³ í•¨(Shouting) ê°ì§€ ë¨¼ì € ì‹¤í–‰
        is_shouting, vol_score = self.detect_shouting(file_path)
        if is_shouting:
            print(f"   ğŸ”Š [ê³ í•¨ ê°ì§€] ìµœëŒ€ ë³¼ë¥¨: {vol_score:.2f} (ê¸°ì¤€ì¹˜ ì´ˆê³¼)")
        
        try:
            # [Step 2] STT ë³€í™˜
            result = self.stt_model.transcribe(
                file_path, 
                language="ko", 
                initial_prompt="ìš•ì„¤, ë¹„ì†ì–´, ì‹¸ì›€, ê±°ì¹œ í‘œí˜„, íŒ¨ë“œë¦½, ê³ í•¨"
            )
            text = result["text"].strip()

            # í™˜ê° ì œê±°
            hallucinations = [
                "ì´ ëŒ€í™”ëŠ” í•œêµ­ì–´", "ì´ ëŒ€í™”ëŠ” ìš•ì„¤", "MBC ë‰´ìŠ¤", "ìë§‰ ë‰´ìŠ¤", "ì‹œì²­í•´ ì£¼ì…”ì„œ"
            ]
            for h in hallucinations:
                if h in text:
                    text = text.replace(h, "").strip()

            print(f"ğŸ—£ï¸ ë³€í™˜ëœ í…ìŠ¤íŠ¸: \"{text}\"")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return None

        if not text:
            # í…ìŠ¤íŠ¸ëŠ” ì—†ëŠ”ë° ì†Œë¦¬ë§Œ ì§€ë¥¸ ê²½ìš° (ë¹„ëª…)
            if is_shouting:
                print("âš ï¸ ëŒ€ì‚¬ ì—†ìŒ + ê³ í•¨ ê°ì§€ -> Level 1 ë¶€ì—¬")
                return {
                    "audio_id": os.path.splitext(filename)[0],
                    "actions": '"shouting,scream"',
                    "intensity": 1
                }
            else:
                print("âš ï¸ ìœ íš¨í•œ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return {
                    "audio_id": os.path.splitext(filename)[0], 
                    "actions": '"silence"', 
                    "intensity": 0
                }

        # [Step 3] í…ìŠ¤íŠ¸ ê°ì •/ìš•ì„¤ ë¶„ì„
        outputs = self.pipe(text)[0]
        best = max(outputs, key=lambda x: x['score'])
        label = best['label']
        score = best['score']

        # [Step 4] ë°ì´í„°ì…‹ ë¼ë²¨ë§ ë¡œì§
        intensity = 0
        actions = []

        # íŒ¨ë“œë¦½ ê°ì§€
        pad_lip_keywords = ["ëŠê¸ˆ", "ë‹ˆì• ë¯¸", "ë‹ˆì• ë¹„", "ì• ë¯¸", "ì• ë¹„", "ëŠê°œë¹„", "ì°½ë…€", "ëŠê²€", "ì— ì°½","ëŠê¸ˆë§ˆ","ë‹ˆë„¤ì—„ë§ˆ","ë‹ˆë„¤ì•„ë¹ ","ë„ˆë„¤ì—„ë§ˆ","ë„ˆë„¤ì•„ë¹ "]
        is_pad_lip = any(keyword in text.replace(" ", "") for keyword in pad_lip_keywords)

        # 1. íŒ¨ë“œë¦½/í˜ì˜¤ í‘œí˜„ (ìµœìš°ì„  Level 3)
        if is_pad_lip or (label not in ['clean', 'ìš•ì„¤', 'ì•…í”Œ/ìš•ì„¤']):
            intensity = 3
            actions.append("hate_speech")
            if is_pad_lip: actions.append("parental_insult")
            
            label_map = {
                'ì—¬ì„±/ê°€ì¡±': 'gender_bias', 'ë‚¨ì„±': 'gender_bias',
                'ì„±ì†Œìˆ˜ì': 'sexual_minority', 'ì¸ì¢…/êµ­ì ': 'racism',
                'ì—°ë ¹': 'ageism', 'ì§€ì—­': 'regional_bias', 'ì¢…êµ': 'religious_bias'
            }
            if label in label_map: actions.append(label_map[label])

        # 2. ì¼ë°˜ ìš•ì„¤
        elif label in ['ìš•ì„¤', 'ì•…í”Œ/ìš•ì„¤']:
            if score < 0.75:
                intensity = 1
                actions.append("slang")
            else:
                intensity = 2
                actions.append("curse")
                actions.append("insult")
        
        # 3. ì •ìƒ ëŒ€í™”
        else: # label == 'clean'
            intensity = 0
            actions.append("talk")

        # ğŸ”¥ [Final] ê³ í•¨(Shouting) ë°˜ì˜ ë¡œì§
        if is_shouting:
            actions.append("shouting")
            # ìš•ì„¤ì´ ì—†ì–´ë„ ì†Œë¦¬ë¥¼ ì§ˆë €ìœ¼ë©´ ìµœì†Œ Level 1 (ì§œì¦/í™”ë‚¨)
            if intensity == 0:
                intensity = 1
                actions.append("annoyance")
            # ì´ë¯¸ ìš•ì„¤(Level 1)ì¸ë° ì†Œë¦¬ê¹Œì§€ ì§ˆë €ìœ¼ë©´ Level 2ë¡œ ê²©ìƒ ê°€ëŠ¥ (ì„ íƒì‚¬í•­)
            # elif intensity == 1:
            #     intensity = 2 

        actions = list(set(actions))
        actions_str = ",".join(actions)

        print(f"ğŸ“Š ìƒì„¸ ë¶„ì„:")
        print(f" - ê°ì§€ëœ ë¼ë²¨: {label} (í™•ë¥ : {score*100:.1f}%)")
        print(f" - ê³ í•¨ ì—¬ë¶€: {is_shouting}")
        print(f" - ìµœì¢… ê°•ë„: Level {intensity}")
        print(f" - ìƒì„±ëœ íƒœê·¸: {actions_str}")

        return {
            "audio_id": os.path.splitext(filename)[0],
            "actions": f'"{actions_str}"',
            "intensity": intensity
        }

    def process_folder(self, input_folder, output_csv):
        extensions = ['*.mp4', '*.mp3', '*.wav', '*.m4a']
        files = []
        for ext in extensions:
            files.extend(glob.glob(os.path.join(input_folder, ext)))
        
        files = sorted(files)
        total = len(files)
        
        print(f"\nğŸš€ ì´ {total}ê°œì˜ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {output_csv}")

        dataset = []

        for idx, file_path in enumerate(files):
            print(f"\n{'='*60}")
            print(f"Progress: [{idx+1}/{total}]")
            
            row = self.analyze_file(file_path)
            
            if row:
                dataset.append(row)

        if dataset:
            df = pd.DataFrame(dataset)
            df = df[["audio_id", "actions", "intensity"]]
            try:
                df.to_csv(output_csv, index=False, encoding='utf-8-sig')
                print(f"\n{'='*60}")
                print(f"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! '{output_csv}' íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                print(df.head())
            except PermissionError:
                print(f"\nâŒ [ì˜¤ë¥˜] '{output_csv}' íŒŒì¼ì´ ì—´ë ¤ìˆìŠµë‹ˆë‹¤. ë‹«ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        else:
            print("\nâš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =========================================================
# â–¶ï¸ ì‹¤í–‰ ì„¤ì •
# =========================================================
if __name__ == "__main__":
    # 1. ë™ì˜ìƒì´ ë“¤ì–´ìˆëŠ” í´ë” ê²½ë¡œ
    INPUT_FOLDER = r"C:\Users\user\.spyder-py3"
    
    # 2. ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ì´ë¦„
    OUTPUT_FILE = "audio_profanity_dataset.csv"

    if os.path.exists(INPUT_FOLDER):
        generator = AudioDatasetGenerator()
        generator.process_folder(INPUT_FOLDER, OUTPUT_FILE)
    else:
        print(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INPUT_FOLDER}")
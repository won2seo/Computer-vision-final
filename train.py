import os
import glob
import numpy as np
import pandas as pd
import librosa
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.utils import Sequence

# =========================================================
# âš™ï¸ ì„¤ì • (Settings)
# =========================================================
CSV_PATH = "audio_profanity_dataset.csv"       # ë°ì´í„°ì…‹ CSV íŒŒì¼ ê²½ë¡œ
AUDIO_FOLDER = r"C:\Users\user\.spyder-py3" # ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ” í´ë”
MODEL_SAVE_PATH = "audio_intensity_model.h5"

# ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì„¤ì •
SAMPLE_RATE = 16000
DURATION = 5  # 5ì´ˆ (ëª¨ë“  ì˜¤ë””ì˜¤ë¥¼ 5ì´ˆë¡œ ë§ì¶¤)
N_MELS = 64   # ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë†’ì´
MAX_LEN = int(SAMPLE_RATE * DURATION / 512) # ì‹œê°„ì¶• ê¸¸ì´ ê³„ì‚° (ì•½ 157)

CLASSES = 4   # ê°•ë„ (0, 1, 2, 3)

# =========================================================
# 1. ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ (Audio -> Image)
# =========================================================
def preprocess_audio(file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì½ì–´ì„œ ë©œ-ìŠ¤í™íŠ¸ë¡œê·¸ë¨(ì´ë¯¸ì§€ í˜•íƒœ)ìœ¼ë¡œ ë³€í™˜"""
    try:
        # 1. ì˜¤ë””ì˜¤ ë¡œë“œ (5ì´ˆ ê¸¸ì´ë¡œ ê³ ì •)
        y, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)
        
        # 2. ê¸¸ì´ê°€ ì§§ìœ¼ë©´ ì±„ìš°ê³ (Padding), ê¸¸ë©´ ìë¦„(Truncate)
        if len(y) < SAMPLE_RATE * DURATION:
            padding = SAMPLE_RATE * DURATION - len(y)
            y = np.pad(y, (0, padding), mode='constant')
        else:
            y = y[:SAMPLE_RATE * DURATION]
            
        # 3. ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë³€í™˜ (ì†Œë¦¬ì˜ ì§€ë¬¸ ë§Œë“¤ê¸°)
        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS)
        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
        
        # 4. ì •ê·œí™” (0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜)
        min_val = mel_spec_db.min()
        max_val = mel_spec_db.max()
        norm_spec = (mel_spec_db - min_val) / (max_val - min_val + 1e-6)
        
        # 5. ì°¨ì› ì¶”ê°€ (CNN ì…ë ¥ í˜•íƒœ: ë†’ì´ x ë„ˆë¹„ x 1)
        # ê²°ê³¼ shape: (64, 157, 1)
        return norm_spec[..., np.newaxis]
        
    except Exception as e:
        print(f"âŒ Error processing {file_path}: {e}")
        return None

# =========================================================
# 2. ë°ì´í„° ì œë„ˆë ˆì´í„° (ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµ)
# =========================================================
class DataGenerator(Sequence):
    def __init__(self, df, audio_folder, batch_size=16, shuffle=True):
        self.df = df
        self.audio_folder = audio_folder
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len(self.df))
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.df) / self.batch_size))

    def __getitem__(self, index):
        # ë°°ì¹˜ë¥¼ ìœ„í•œ ì¸ë±ìŠ¤ ì„ íƒ
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
        
        X = []
        y = []
        
        for k in indexes:
            row = self.df.iloc[k]
            file_id = str(row['audio_id'])
            label = int(row['intensity'])
            
            # íŒŒì¼ ì°¾ê¸° (í™•ì¥ìê°€ mp4, mp3, wav ì¤‘ ë¬´ì—‡ì¸ì§€ ëª¨ë¥´ë¯€ë¡œ ê²€ìƒ‰)
            search_path = os.path.join(self.audio_folder, f"{file_id}.*")
            found_files = glob.glob(search_path)
            
            if not found_files:
                # íŒŒì¼ì„ ëª» ì°¾ìœ¼ë©´ ê±´ë„ˆëœ€ (0ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ìŠ¤í‚µ)
                continue
                
            file_path = found_files[0] # ì²« ë²ˆì§¸ ë§¤ì¹­ íŒŒì¼ ì‚¬ìš©
            
            # ì „ì²˜ë¦¬
            data = preprocess_audio(file_path)
            if data is not None and data.shape == (N_MELS, MAX_LEN+1, 1): # shape ë³´ì •
                 X.append(data)
                 y.append(label)
            elif data is not None:
                # í¬ê¸°ê°€ ì•ˆ ë§ìœ¼ë©´ ë¦¬ì‚¬ì´ì¦ˆ
                import cv2
                resized = cv2.resize(data, (MAX_LEN, N_MELS))
                X.append(resized[..., np.newaxis])
                y.append(label)

        return np.array(X), np.array(y)

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indexes)

# =========================================================
# 3. ëª¨ë¸ ì„¤ê³„ (CNN)
# =========================================================
def build_model(input_shape, num_classes):
    model = Sequential([
        # ì²« ë²ˆì§¸ í•©ì„±ê³± ì¸µ
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D((2, 2)),
        BatchNormalization(),
        
        # ë‘ ë²ˆì§¸ í•©ì„±ê³± ì¸µ
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Dropout(0.3),
        
        # ì„¸ ë²ˆì§¸ í•©ì„±ê³± ì¸µ
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Dropout(0.3),
        
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.4),
        
        # ì¶œë ¥ì¸µ (0, 1, 2, 3 ë¶„ë¥˜)
        Dense(num_classes, activation='softmax')
    ])
    
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy', # 0,1,2,3 ì •ìˆ˜ ë¼ë²¨ìš©
                  metrics=['accuracy'])
    return model

# =========================================================
# 4. ë©”ì¸ ì‹¤í–‰ë¶€
# =========================================================
if __name__ == "__main__":
    # 1. CSV ë¡œë“œ
    if not os.path.exists(CSV_PATH):
        print(f"âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {CSV_PATH}")
        exit()
        
    df = pd.read_csv(CSV_PATH)
    print(f"ğŸ“Š ì „ì²´ ë°ì´í„° ê°œìˆ˜: {len(df)}ê°œ")
    
    # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ í•™ìŠµ ë¶ˆê°€
    if len(df) < 10:
        print("âš ï¸ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ 10ê°œ ì´ìƒì˜ íŒŒì¼ì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
        exit()

    # 2. í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬ (8:2)
    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=None)
    
    print(f"   - í•™ìŠµìš©: {len(train_df)}ê°œ")
    print(f"   - ê²€ì¦ìš©: {len(val_df)}ê°œ")

    # 3. ì œë„ˆë ˆì´í„° ìƒì„±
    train_gen = DataGenerator(train_df, AUDIO_FOLDER, batch_size=8)
    val_gen = DataGenerator(val_df, AUDIO_FOLDER, batch_size=8)
    
    # 4. ëª¨ë¸ ìƒì„±
    # ì…ë ¥ shape ê³„ì‚° (ìë™) -> (64, 157, 1) ì •ë„ ì˜ˆìƒ
    # 1. mp4 íŒŒì¼ë§Œ ì°¾ë„ë¡ ë³€ê²½
    sample_files = glob.glob(os.path.join(AUDIO_FOLDER, "*.mp4"))

    # (ë§Œì•½ mp3ë¥¼ ì“´ë‹¤ë©´ "*.mp3"ë¡œ ë°”ê¾¸ê±°ë‚˜, ë‘˜ ë‹¤ ì°¾ê²Œ í•´ì•¼ í•¨)
    if not sample_files:
        sample_files = glob.glob(os.path.join(AUDIO_FOLDER, "*.mp3"))

    if not sample_files:
        print("âŒ í´ë”ì— ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤!")
        exit()

    # 2. ì°¾ì€ íŒŒì¼ ì¤‘ ì²« ë²ˆì§¸ ê²ƒìœ¼ë¡œ í˜•íƒœ íŒŒì•…
    dummy_data = preprocess_audio(sample_files[0])
    input_shape = dummy_data.shape
    print(f"ğŸ§  ëª¨ë¸ ì…ë ¥ í˜•íƒœ: {input_shape}")
    
    model = build_model(input_shape, CLASSES)
    model.summary()

    # 5. í•™ìŠµ ì‹œì‘
    checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_accuracy', save_best_only=True, verbose=1)
    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

    print("\nğŸš€ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤... (Ctrl+Cë¡œ ì¤‘ë‹¨ ê°€ëŠ¥)")
    history = model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=30, # 30ë²ˆ ë°˜ë³µ í•™ìŠµ
        callbacks=[checkpoint, early_stop]
    )

    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {MODEL_SAVE_PATH}")
    
    # 1. í•™ìŠµì´ ëë‚œ í›„ ë¬´ì¡°ê±´ ê°•ì œë¡œ ì €ì¥í•˜ê¸°
    model.save(MODEL_SAVE_PATH)
    
    # 2. íŒŒì¼ì´ ì–´ë””ì— ì €ì¥ëëŠ”ì§€ ì •í™•í•œ ì£¼ì†Œë¥¼ ì•Œë ¤ì£¼ê¸°
    import os
    print("\n" + "="*50)
    print(f"ğŸ‰ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“‚ íŒŒì¼ ìœ„ì¹˜: {os.path.abspath(MODEL_SAVE_PATH)}")
    print("="*50 + "\n")
import os
import cv2
import glob
import pickle
import random

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

corner_keys = ["Center", "Left_up", "Left_down", "Right_up", "Right_down"]

Debug_Print_AUG = False


# ============================================================
# ğŸ”¥ Augmentation í•¨ìˆ˜
# ============================================================
def augment_frame(arr):
    """
    arr: float32, [H, W, 3], ê°’ ë²”ìœ„ [0, 1]
    ê°„ë‹¨í•œ augmentation(ì¢Œìš° ë°˜ì „, ë°ê¸° ë³€í™”, ë…¸ì´ì¦ˆ)ì„ ì ìš©
    """
    # ì¢Œìš° ë°˜ì „
    if random.random() < 0.5:
        arr = np.fliplr(arr)

    # ë°ê¸° ì¡°ì ˆ (0.8 ~ 1.2 ë°°)
    if random.random() < 0.5:
        factor = 0.8 + random.random() * 0.4
        arr = np.clip(arr * factor, 0.0, 1.0)

    # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì•½ê°„ ì¶”ê°€
    if random.random() < 0.3:
        noise = np.random.normal(0, 0.02, arr.shape).astype(np.float32)
        arr = np.clip(arr + noise, 0.0, 1.0)

    return arr


def extract_and_save_frames(video_path, video_id, figures_root,
                            fix_len=None, skip_frames=None):
    """
    ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•´ì„œ
    data/raw_frames/{video_id}/frame_0.jpg ì´ëŸ° ì‹ìœ¼ë¡œ ì €ì¥.
    """
    video_figures_path = os.path.join(figures_root, video_id)
    os.makedirs(video_figures_path, exist_ok=True)

    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    if fix_len is not None and fix_len > 0 and total_frames > 0:
        # ì „ì²´ í”„ë ˆì„ ì¤‘ fix_len ê°œë¥¼ ê· ë“±í•˜ê²Œ ë½‘ê¸° ìœ„í•œ step
        step = max(total_frames // fix_len, 1)
    else:
        step = 1
        fix_len = None  # ì œí•œ ë‘ì§€ ì•ŠìŒ

    seq_len = 0
    idx = 0
    frame_files = []

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if idx % step == 0:
            frame_file = os.path.join(video_figures_path, f"frame_{seq_len}.jpg")
            cv2.imwrite(frame_file, frame)
            frame_files.append(frame_file)
            seq_len += 1
            if fix_len is not None and seq_len >= fix_len:
                break

        idx += 1

    cap.release()

    video_images = dict(
        images_path=video_figures_path,
        name=video_id,
        images_files=frame_files,
        sequence_length=seq_len
    )
    return video_images


def createDataset(datasets_video_path, figure_output_path, fix_len, force=False):
    """
    ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€:
    - datasets_video_path: dict
        {
          "violent": "data/violence-detection-dataset/violent",
          "non-violent": "data/violence-detection-dataset/non-violent"
        }
    - figure_output_path: "data/raw_frames"
    - fix_len: ì‹œí€€ìŠ¤ ê¸¸ì´ (ì˜ˆ: 20)

    ë°˜í™˜:
    train_path, valid_path, test_path,
    train_y, valid_y, test_y,
    avg_length
    """
    labels_csv = os.path.join("data", "violence_intensity_labels.csv")
    labels_df = pd.read_csv(labels_csv)

    # video_id -> intensity (0~3)
    video2intensity = dict(zip(labels_df["video_id"], labels_df["intensity"]))

    videos_seq_length = []
    videos_frames_paths = []
    videos_labels = []

    for cls_key, cls_root in datasets_video_path.items():
        # cls_key: "violent" ë˜ëŠ” "non-violent"
        for cam in ["cam1", "cam2"]:
            cam_dir = os.path.join(cls_root, cam)
            if not os.path.isdir(cam_dir):
                continue

            for filename in sorted(os.listdir(cam_dir)):
                if not filename.lower().endswith(".mp4"):
                    continue

                base = os.path.splitext(filename)[0]  # "1", "2", ...
                if cls_key == "violent":
                    prefix = "violent"
                else:
                    # CSVì—ì„œ nonviolent_ ë¡œ ë§Œë“¤ì—ˆìœ¼ë¯€ë¡œ í•˜ì´í”ˆ ì—†ëŠ” ì´ë¦„ ì‚¬ìš©
                    prefix = "nonviolent"

                video_id = f"{prefix}_{cam}_{base}"

                if video_id not in video2intensity:
                    # ë¼ë²¨ CSVì— ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ
                    continue

                label = int(video2intensity[video_id])

                # í”„ë ˆì„ ì €ì¥ ê²½ë¡œ
                video_figures_path = os.path.join(figure_output_path, video_id)
                summary_pkl = os.path.join(video_figures_path, "video_summary.pkl")

                if os.path.isfile(summary_pkl) and not force:
                    with open(summary_pkl, "rb") as f:
                        video_images = pickle.load(f)
                else:
                    video_path = os.path.join(cam_dir, filename)
                    video_images = extract_and_save_frames(
                        video_path, video_id, figure_output_path, fix_len=fix_len
                    )
                    video_images["label"] = label
                    os.makedirs(video_figures_path, exist_ok=True)
                    with open(summary_pkl, "wb") as f:
                        pickle.dump(video_images, f, pickle.HIGHEST_PROTOCOL)

                videos_seq_length.append(video_images["sequence_length"])
                videos_frames_paths.append(video_images["images_path"])
                videos_labels.append(video_images["label"])

    avg_length = int(float(sum(videos_seq_length)) / max(len(videos_seq_length), 1))

    # stratifyë¡œ ê°•ë„ ë¶„í¬ ìœ ì§€
    train_path, test_path, train_y, test_y = train_test_split(
        videos_frames_paths, videos_labels, test_size=0.20,
        random_state=42, stratify=videos_labels
    )
    train_path, valid_path, train_y, valid_y = train_test_split(
        train_path, train_y, test_size=0.20,
        random_state=42, stratify=train_y
    )

    return train_path, valid_path, test_path, train_y, valid_y, test_y, avg_length


def frame_loader(frames, figure_shape, to_norm=True):
    X = []
    for f in frames:
        img = load_img(f, target_size=(figure_shape, figure_shape))
        arr = img_to_array(img)
        if to_norm:
            arr = arr.astype("float32") / 255.0
        X.append(arr)
    return np.array(X, dtype="float32")


def crop_img(img, figure_shape, percentage=0.8, corner="Center"):
    """
    ê°„ë‹¨í•œ í¬ë¡­ í•¨ìˆ˜. (cornerëŠ” Centerë§Œ ì‹¤ì§ˆì ìœ¼ë¡œ ì‚¬ìš©)
    """
    h, w, c = img.shape
    target = figure_shape

    # ì¤‘ì•™ í¬ë¡­
    new_h = int(h * percentage)
    new_w = int(w * percentage)
    y_start = max((h - new_h) // 2, 0)
    x_start = max((w - new_w) // 2, 0)
    cropped = img[y_start:y_start + new_h, x_start:x_start + new_w, :]
    resized = cv2.resize(cropped, (target, target))
    return resized.astype(np.float32)


def natural_sort(l):
    import re
    convert = lambda text: int(text) if text.isdigit() else text
    alphanum_key = lambda key: [
        convert(c) for c in re.split("([0-9]+)", key)
    ]
    return sorted(l, key=alphanum_key)


def get_sequences(data_paths, labels, figure_shape, seq_length,
                  classes=1, use_augmentation=False, use_crop=True, crop_x_y=None):
    """
    test setìš©: ëª¨ë“  ì‹œí€€ìŠ¤ë¥¼ í•œ ë²ˆì— ë©”ëª¨ë¦¬ë¡œ ë¡œë“œ.
    testì—ì„œëŠ” augmentation ì‚¬ìš© X (use_augmentation ë¯¸ì‚¬ìš©).
    """
    X, y = [], []
    for path, label in zip(data_paths, labels):
        frames = natural_sort(
            glob.glob(os.path.join(path, "frame_*.jpg"))
        )
        if len(frames) == 0:
            continue

        # ë’¤ì—ì„œ seq_lengthê°œ ì‚¬ìš© (ë¶€ì¡±í•˜ë©´ ì•ì—ì„œë¶€í„° ì±„ì›€)
        if len(frames) >= seq_length:
            frames = frames[-seq_length:]
        else:
            # ë¶€ì¡±í•œ ë§Œí¼ ì²« í”„ë ˆì„ì„ ë°˜ë³µí•´ì„œ padding
            frames = [frames[0]] * (seq_length - len(frames)) + frames

        seq = frame_loader(frames, figure_shape, to_norm=True)
        X.append(seq)
        y.append(label)

    X = np.array(X, dtype="float32")
    if classes > 1:
        y = to_categorical(np.array(y), num_classes=classes)
    else:
        y = np.array(y)
    return X, y


def data_generator(data_paths, labels, batch_size, figure_shape, seq_length,
                   use_aug, use_crop, crop_x_y, classes=1):
    """
    train/validationìš© generator
    use_aug=Trueì¼ ë•Œ ìœ„ì—ì„œ ì •ì˜í•œ augment_frameì„ ì‚¬ìš©í•´
    ë°ì´í„° ì¦ê°•ì„ ìˆ˜í–‰.
    """
    n = len(data_paths)
    while True:
        idxs = np.arange(n)
        np.random.shuffle(idxs)
        for start in range(0, n, batch_size):
            batch_idx = idxs[start:start + batch_size]
            X_batch, y_batch = [], []
            for i in batch_idx:
                path = data_paths[i]
                label = labels[i]

                frames = natural_sort(
                    glob.glob(os.path.join(path, "frame_*.jpg"))
                )
                if len(frames) == 0:
                    continue

                if len(frames) >= seq_length:
                    frames_sel = frames[-seq_length:]
                else:
                    frames_sel = [frames[0]] * (seq_length - len(frames)) + frames

                imgs = []
                for f in frames_sel:
                    img = load_img(f, target_size=(figure_shape, figure_shape))
                    arr = img_to_array(img)
                    arr = arr.astype("float32") / 255.0

                    # ğŸ”¥ train/valì—ì„œë§Œ augmentation ì ìš©
                    if use_aug:
                        arr = augment_frame(arr)

                    imgs.append(arr)
                X_batch.append(np.array(imgs, dtype="float32"))
                y_batch.append(label)

            if len(X_batch) == 0:
                continue

            X_batch = np.array(X_batch, dtype="float32")
            if classes > 1:
                y_batch = to_categorical(np.array(y_batch), num_classes=classes)
            else:
                y_batch = np.array(y_batch)

            yield X_batch, y_batch


def data_generator_files(data, labels, batch_size):
    """
    (ì•ˆ ì“°ê³  ìˆì§€ë§Œ, í˜¹ì‹œ ê¸°ì¡´ ì½”ë“œì—ì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìœ¼ë‹ˆ ìœ ì§€)
    """
    while True:
        indexes = np.arange(len(data))
        np.random.shuffle(indexes)
        select_indexes = indexes[:batch_size]
        X = [data[i] for i in select_indexes]
        y = [labels[i] for i in select_indexes]
        yield X, y

